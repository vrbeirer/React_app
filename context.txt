

# ğŸ”µ Q1. What is the intuition of a linear model?

A linear model assumes the output changes in a straight-line way when inputs change.
Like â€œmore square feet â†’ more house price.â€ 

----------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q2. Explain the linear formula.

`h(X) = Î¸0 + Î¸1X1`
Î¸0 is starting value.
Î¸1 tells how much output changes when input changes. 

-----------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q3. How to implement general linear formula in Python?

Add bias + sum of (weight Ã— feature).
This is done in `_compute_z()` in the PDF. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q4. Structure of X and y

* X is a list of samples. Each sample is a list of features.
* y is a list of labels (one per sample). 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q5. Why linear output is not good for classification?

Because it can be any number, like 300 or -50.
A class needs a probability between 0 and 1. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q6. What modification converts linear â†’ logistic?

Wrap the linear output z inside a Sigmoid function. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q7. Sigmoid formula and behavior

`g(z) = 1 / (1 + e^-z)`
Big positive z â†’ output near 1.
Big negative z â†’ output near 0.
z=0 â†’ output = 0.5. 

----------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q8. Python implementation of Sigmoid

Same as in the PDFâ€™s `_sigmoid` function, with checks for big numbers. 

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q9. Why sigmoid output is a valid probability?

Because it comes from **odds** and **log-odds**, which map naturally into [0,1].
The math links linear z â†’ probability p. 

------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q10. Probability, Odds, Log-Odds

* Probability: p (0 to 1)
* Odds: p/(1-p) (0 to âˆ)
* Log-Odds: log(p/(1-p)) (-âˆ to âˆ) 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q11. Derive sigmoid (simple explanation)

Set log-odds equal to linear z.
Solve the equation for p.
You get the sigmoid formula. 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q12. How is the full logistic model trained?

Two things:

1. **Cost Function:** Measures how wrong prediction is (log-loss).
2. **Gradient Descent:** Adjusts weights step-by-step to lower the cost. 

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q13. Full class code

Exactly as shown in the PDF.
It contains: sigmoid, cost, gradients, fit, predict. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q14. How to test the model?

Use a simple dataset (hours studied).
Train the model.
Predict on new samples. 

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q15. Expected output of experiment

* Cost goes down over iterations.
* Final theta values learned.
* Predictions:

  * Small hours â†’ fail
  * Large hours â†’ pass
  * Middle ~3 hours â†’ around 0.5 probability. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q16. Main limitation of this pure Python version

It is slow because of loops.
Libraries like NumPy are much faster. 

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ”µ Q17. What happens if you change learning rate or iterations?

* Very high learning rate â†’ model explodes.
* Very low â†’ learning is very slow.
* Very few iterations â†’ underfitting. 

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
